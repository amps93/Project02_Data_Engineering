{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0792555-2db7-4bf8-8694-7f6b5a5a8e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### 어니언 안국점\n",
      "no review in crawling\n",
      "#### 황생가칼국수\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ba8be0d80c2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-ba8be0d80c2e>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mlists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'종로구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'중구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'용산구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'성동구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'광진구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'동대문구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'중랑구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'성북구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'강북구 맛집'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ba8be0d80c2e>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(place)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# 검색된 첫 페이지 장소 목록 크롤링하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mcrawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0msearch_area\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ba8be0d80c2e>\u001b[0m in \u001b[0;36mcrawling\u001b[1;34m(place, place_lists)\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child('\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m')'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m                     \u001b[0mextract_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                     \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "##############################################################  ############\n",
    "##################### variable related selenium ##########################\n",
    "##########################################################################\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "# chromedriver_path = \"chromedriver\"\n",
    "# driver = webdriver.Chrome(os.path.join(os.getcwd(), chromedriver_path), options=options)  # chromedriver 열기\n",
    "\n",
    "rating_df = pd.DataFrame()\n",
    "restaurant_df = pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    global driver, load_wb, review_num\n",
    "\n",
    "    driver.implicitly_wait(4)  # 렌더링 될때까지 기다린다 4초\n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "\n",
    "    # 검색할 목록\n",
    "    lists = ['종로구 맛집', '중구 맛집', '용산구 맛집', '성동구 맛집', '광진구 맛집', '동대문구 맛집', '중랑구 맛집', '성북구 맛집', '강북구 맛집']\n",
    "    for list in lists:\n",
    "        search(list)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"finish\")\n",
    "\n",
    "\n",
    "def search(place):\n",
    "    global driver\n",
    "\n",
    "    search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')  # 검색 창\n",
    "    search_area.send_keys(place)  # 검색어 입력\n",
    "    driver.find_element_by_xpath('//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER) # 더보기\n",
    "    sleep(1)\n",
    "\n",
    "    # 검색된 정보가 있는 경우에만 탐색\n",
    "    # 1번 페이지 place list 읽기\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem') # 검색된 장소 목록\n",
    "\n",
    "    # 검색된 첫 페이지 장소 목록 크롤링하기\n",
    "    crawling(place, place_lists)\n",
    "    search_area.clear()\n",
    "\n",
    "    # 전체 페이지\n",
    "    while True:\n",
    "        try:\n",
    "#             driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER)\n",
    "#             sleep(1)\n",
    "            # 2~ 5페이지 읽기\n",
    "            for i in range(2, 6):\n",
    "                # 페이지 넘기기\n",
    "                xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "                driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                place_lists = soup.select('.placelist > .PlaceItem') # 장소 목록 list\n",
    "                \n",
    "                crawling(place, place_lists)\n",
    "                \n",
    "                # 다음 페이지 넘기기\n",
    "                if i==5:\n",
    "                    driver.find_element_by_xpath('//*[@id=\"info.search.page.next\"]').send_keys(Keys.ENTER)\n",
    "\n",
    "        except ElementNotInteractableException:\n",
    "            print('end page')\n",
    "            break\n",
    "#         finally:\n",
    "#             search_area.clear()\n",
    "\n",
    "\n",
    "def crawling(place, place_lists):\n",
    "    \"\"\"\n",
    "    페이지 목록을 받아서 크롤링 하는 함수\n",
    "    :param place: 리뷰 정보 찾을 장소이름\n",
    "    \"\"\"\n",
    "    \n",
    "    global restaurant_df\n",
    "\n",
    "    while_flag = False\n",
    "    for i, place in enumerate(place_lists):\n",
    "        # 광고에 따라서 index 조정해야함\n",
    "        #if i >= 3:\n",
    "         #   i += 1\n",
    "\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text  # place name\n",
    "        place_address = place.select('.info_item > .addr > p')[0].text  # place address\n",
    "        place_local = place.select('.info_item > .addr > .lot_number')[0].text\n",
    "        place_category = place.select('.head_item > .subcategory')[0].text\n",
    "        place_detail = place.select('.info_item > .contact> .moreview')[0].get('href') # place detail\n",
    "        \n",
    "        row = {\"ItemID\":place_name, \"address\": place_address, \"local\" : place_local, \"category\": place_category}\n",
    "        row = pd.DataFrame(row, index=[1])\n",
    "        restaurant_df = restaurant_df.append(row, ignore_index=True)\n",
    "        \n",
    "        driver.execute_script('window.open(\"about:blank\", \"_blank\");')\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        driver.get(place_detail) # 상세정보 탭으로 변환\n",
    "        sleep(1)\n",
    "\n",
    "#         detail_page_xpath = '//*[@id=\"info.search.place.list\"]/li[' + str(i + 1) + ']/div[5]/div[4]/a[1]'\n",
    "#         driver.find_element_by_xpath(detail_page_xpath).send_keys(Keys.ENTER)\n",
    "#         driver.switch_to.window(driver.window_handles[-1])  \n",
    "        \n",
    "        print('####', place_name)\n",
    "\n",
    "        # 첫 페이지\n",
    "        extract_review(place_name) # 리뷰 추출\n",
    "\n",
    "        # 2-5 페이지\n",
    "        idx = 3\n",
    "        try:\n",
    "            page_num = len(driver.find_elements_by_class_name('link_page')) # 페이지 수 찾기\n",
    "            \n",
    "            for i in range(page_num-1):\n",
    "                # css selector를 이용해 페이지 버튼 누르기\n",
    "                driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "                extract_review(place_name)\n",
    "                idx += 1\n",
    "            driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 5페이지가 넘는 경우 다음 버튼 누르기\n",
    "            sleep(1)\n",
    "            extract_review(place_name) # 리뷰 추출\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            print(\"no review in crawling\")\n",
    "\n",
    "        # 그 이후 페이지\n",
    "        while True:\n",
    "            idx = 4\n",
    "            try:\n",
    "                page_num = len(driver.find_elements_by_class_name('link_page')) #페이지 수 찾기\n",
    "                \n",
    "                for i in range(page_num-1):\n",
    "                    driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                    sleep(1)\n",
    "                    extract_review(place_name)\n",
    "                    idx += 1\n",
    "                driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\n",
    "                sleep(1)\n",
    "                extract_review(place_name) # 리뷰 추출\n",
    "                \n",
    "            except (NoSuchElementException, ElementNotInteractableException):\n",
    "                print(\"no review in crawling\")\n",
    "                break\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])  # 검색 탭으로 전환\n",
    "\n",
    "\n",
    "def extract_review(place_name):\n",
    "    global driver, rating_df\n",
    "\n",
    "    ret = True\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 첫 페이지 리뷰 목록 찾기\n",
    "    review_lists = soup.select('.list_evaluation > li')\n",
    "\n",
    "    # 리뷰가 있는 경우\n",
    "    if len(review_lists) != 0:\n",
    "        for i, review in enumerate(review_lists):\n",
    "            comment = review.select('.txt_comment > span') # 리뷰\n",
    "            rating = review.select('.grade_star > em') # 별점\n",
    "            user_id = review.select('.append_item > a[data-userid]') # user 정보 html 파싱\n",
    "            timestamp = review.select(' div > span.time_write') #시간정보\n",
    "            \n",
    "            val = ''\n",
    "            if len(comment) != 0:\n",
    "                if len(rating) != 0:\n",
    "                    val = comment[0].text + '/' + rating[0].text.replace('점', '')\n",
    "                else:\n",
    "                    val = comment[0].text + '/0'\n",
    "#                 print(val)\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    if(user_id == NULL and rating ==NULL):\n",
    "                        row = {\"ItemID\":place_name, \"UserID\": None, \"review\" : None,\n",
    "                               \"Rating\":None, \"Timestamp\":timestamp[0].text}\n",
    "                        row = pd.DataFrame(row, index=[i])\n",
    "                        rating_df = rating_df.append(row, ignore_index=True)\n",
    "                        \n",
    "                    elif(user_id == NULL):\n",
    "                        row = {\"ItemID\":place_name, \"UserID\": None, \"review\" : None,\n",
    "                               \"Rating\":None, \"Timestamp\":timestamp[0].text}\n",
    "                        row = pd.DataFrame(row, index=[i])\n",
    "                        rating_df = rating_df.append(row, ignore_index=True)\n",
    "                        \n",
    "                    elif(rating ==NULL):\n",
    "                        row = {\"ItemID\":place_name, \"UserID\": None, \"review\" : None,\n",
    "                               \"Rating\":None, \"Timestamp\":timestamp[0].text}\n",
    "                        row = pd.DataFrame(row, index=[i])\n",
    "                        rating_df = rating_df.append(row, ignore_index=True)\n",
    "                        \n",
    "                    else:\n",
    "                        row = {\"ItemID\":place_name, \"UserID\":user_id[0].get('data-userid'), \"review\" : comment[0].text,\n",
    "                               \"Rating\":rating[0].text.replace('점', ''), \"Timestamp\":timestamp[0].text}\n",
    "                        row = pd.DataFrame(row, index=[i])\n",
    "                        rating_df = rating_df.append(row, ignore_index=True)    \n",
    "            \n",
    "                except:\n",
    "                    row = {\"ItemID\":place_name, \"UserID\":None, \"review\" : None,\n",
    "                           \"Rating\": None, \"Timestamp\":timestamp[0].text}\n",
    "                    row = pd.DataFrame(row, index=[i])\n",
    "                    rating_df = rating_df.append(row,ignore_index=True)                \n",
    "                \n",
    "                \n",
    "#                 try:\n",
    "#                     row = {\"ItemID\":place_name, \"UserID\":user_id[0].get('data-userid'), \"review\" : comment[0].text,\n",
    "#                            \"Rating\":rating[0].text.replace('점', ''), \"Timestamp\":timestamp[0].text}\n",
    "#                     row = pd.DataFrame(row, index=[i])\n",
    "#                     rating_df = rating_df.append(row, ignore_index=True)\n",
    "            \n",
    "#                 except:\n",
    "#                     row = {\"ItemID\":place_name, \"UserID\":None, \"review\" : None,\n",
    "#                            \"Rating\": None, \"Timestamp\":timestamp[0].text}\n",
    "#                     row = pd.DataFrame(row, index=[i])\n",
    "#                     rating_df = rating_df.append(row,ignore_index=True)\n",
    "                \n",
    "                \n",
    "    else:\n",
    "        print('no review in extract')\n",
    "        ret = False\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "838a97b0-72c1-40e8-ba46-6622216ccbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>조연탄</td>\n",
       "      <td>k9hsnf</td>\n",
       "      <td>헉 가게가 좀 부산스럽고 종업원분들이 극 인싸이싱거같아요 그거랑 별개로 맛은 정말 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021.08.03.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>조연탄</td>\n",
       "      <td>o9qv2m</td>\n",
       "      <td>어엄청 친절하셔유! 맛있어여 또 갈거예요</td>\n",
       "      <td>5</td>\n",
       "      <td>2021.06.25.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>조연탄</td>\n",
       "      <td>1cbc382</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>2021.06.23.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>조연탄</td>\n",
       "      <td>13n8k41</td>\n",
       "      <td>찐맛집</td>\n",
       "      <td>5</td>\n",
       "      <td>2021.06.19.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조연탄</td>\n",
       "      <td>1fio525</td>\n",
       "      <td>내 최애 고기집</td>\n",
       "      <td>5</td>\n",
       "      <td>2021.06.15.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ItemID   UserID                                             review Rating  \\\n",
       "0    조연탄   k9hsnf  헉 가게가 좀 부산스럽고 종업원분들이 극 인싸이싱거같아요 그거랑 별개로 맛은 정말 ...      5   \n",
       "1    조연탄   o9qv2m                             어엄청 친절하셔유! 맛있어여 또 갈거예요      5   \n",
       "2    조연탄  1cbc382                                                         5   \n",
       "3    조연탄  13n8k41                                                찐맛집      5   \n",
       "4    조연탄  1fio525                                           내 최애 고기집      5   \n",
       "\n",
       "     Timestamp  \n",
       "0  2021.08.03.  \n",
       "1  2021.06.25.  \n",
       "2  2021.06.23.  \n",
       "3  2021.06.19.  \n",
       "4  2021.06.15.  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1765db00-ba6e-4302-bde1-89183e0cec3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>address</th>\n",
       "      <th>local</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>조연탄</td>\n",
       "      <td>서울 강서구 곰달래로60길 29</td>\n",
       "      <td>(지번) 화곡동 782-12</td>\n",
       "      <td>육류,고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>먹자대게</td>\n",
       "      <td>서울 양천구 목동서로 213 세신비젼프라자 1층 108호</td>\n",
       "      <td>(지번) 목동 923</td>\n",
       "      <td>게,대게</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>착한낙지 목동점</td>\n",
       "      <td>서울 양천구 국회대로 289</td>\n",
       "      <td>(지번) 목동 802-9</td>\n",
       "      <td>해물,생선</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일미락 목동본점</td>\n",
       "      <td>서울 양천구 목동동로 226-16 1층</td>\n",
       "      <td>(지번) 목동 406-126</td>\n",
       "      <td>육류,고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>원조소금구이</td>\n",
       "      <td>서울 강서구 곰달래로60길 5 1층</td>\n",
       "      <td>(지번) 화곡동 781-12</td>\n",
       "      <td>육류,고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>엉털네숯불꼼장어</td>\n",
       "      <td>서울 양천구 등촌로 36</td>\n",
       "      <td>(지번) 목동 792-2</td>\n",
       "      <td>장어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>더아리엘 목동점</td>\n",
       "      <td>서울 양천구 오목로 300 현대하이페리온2차 206동 지하1층 109~115호</td>\n",
       "      <td>(지번) 목동 961-1</td>\n",
       "      <td>뷔페</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>양천옥설렁탕</td>\n",
       "      <td>서울 양천구 등촌로 86</td>\n",
       "      <td>(지번) 목동 730-2</td>\n",
       "      <td>설렁탕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>오목집 목동본점</td>\n",
       "      <td>서울 양천구 목동서로 155 목동파라곤 지하상가 45호</td>\n",
       "      <td>(지번) 목동 917</td>\n",
       "      <td>족발,보쌈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>스타벅스 화곡DT점</td>\n",
       "      <td>서울 강서구 등촌로 57</td>\n",
       "      <td>(지번) 화곡동 772-67</td>\n",
       "      <td>커피전문점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>쭉심 목동사거리점</td>\n",
       "      <td>서울 강서구 등촌로3길 14</td>\n",
       "      <td>(지번) 화곡동 780-27</td>\n",
       "      <td>해물,생선</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>팔각도 목동본점</td>\n",
       "      <td>서울 양천구 목동동로 266-1 금강빌딩 1층</td>\n",
       "      <td>(지번) 목동 406-227</td>\n",
       "      <td>닭요리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>우장창창 목동본점</td>\n",
       "      <td>서울 양천구 목동중앙서로1길 17</td>\n",
       "      <td>(지번) 목동 792-9</td>\n",
       "      <td>곱창,막창</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>개성집</td>\n",
       "      <td>서울 양천구 목동중앙서로 48</td>\n",
       "      <td>(지번) 목동 799-7</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>은행골 목동점</td>\n",
       "      <td>서울 양천구 목동서로 155</td>\n",
       "      <td>(지번) 목동 917</td>\n",
       "      <td>초밥,롤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>강릉스낵</td>\n",
       "      <td>서울 양천구 목동동로 228-2 1층</td>\n",
       "      <td>(지번) 목동 406-65</td>\n",
       "      <td>실내포장마차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>만복순대국</td>\n",
       "      <td>서울 양천구 목동로 219 1층</td>\n",
       "      <td>(지번) 신정동 899-5</td>\n",
       "      <td>순대</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>닥터로빈 목동점</td>\n",
       "      <td>서울 양천구 오목로 299</td>\n",
       "      <td>(지번) 목동 962</td>\n",
       "      <td>양식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>락희안 목동점</td>\n",
       "      <td>서울 양천구 오목로 330 2,3층</td>\n",
       "      <td>(지번) 목동 405-285</td>\n",
       "      <td>중화요리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>구도커피</td>\n",
       "      <td>서울 강서구 등촌로35길 121 1,2층</td>\n",
       "      <td>(지번) 등촌동 565-18</td>\n",
       "      <td>커피전문점</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ItemID                                      address            local  \\\n",
       "0          조연탄                            서울 강서구 곰달래로60길 29  (지번) 화곡동 782-12   \n",
       "1         먹자대게              서울 양천구 목동서로 213 세신비젼프라자 1층 108호      (지번) 목동 923   \n",
       "2     착한낙지 목동점                              서울 양천구 국회대로 289    (지번) 목동 802-9   \n",
       "3     일미락 목동본점                        서울 양천구 목동동로 226-16 1층  (지번) 목동 406-126   \n",
       "4       원조소금구이                          서울 강서구 곰달래로60길 5 1층  (지번) 화곡동 781-12   \n",
       "5     엉털네숯불꼼장어                                서울 양천구 등촌로 36    (지번) 목동 792-2   \n",
       "6     더아리엘 목동점  서울 양천구 오목로 300 현대하이페리온2차 206동 지하1층 109~115호    (지번) 목동 961-1   \n",
       "7       양천옥설렁탕                                서울 양천구 등촌로 86    (지번) 목동 730-2   \n",
       "8     오목집 목동본점               서울 양천구 목동서로 155 목동파라곤 지하상가 45호      (지번) 목동 917   \n",
       "9   스타벅스 화곡DT점                                서울 강서구 등촌로 57  (지번) 화곡동 772-67   \n",
       "10   쭉심 목동사거리점                              서울 강서구 등촌로3길 14  (지번) 화곡동 780-27   \n",
       "11    팔각도 목동본점                    서울 양천구 목동동로 266-1 금강빌딩 1층  (지번) 목동 406-227   \n",
       "12   우장창창 목동본점                           서울 양천구 목동중앙서로1길 17    (지번) 목동 792-9   \n",
       "13         개성집                             서울 양천구 목동중앙서로 48    (지번) 목동 799-7   \n",
       "14     은행골 목동점                              서울 양천구 목동서로 155      (지번) 목동 917   \n",
       "15        강릉스낵                         서울 양천구 목동동로 228-2 1층   (지번) 목동 406-65   \n",
       "16       만복순대국                            서울 양천구 목동로 219 1층   (지번) 신정동 899-5   \n",
       "17    닥터로빈 목동점                               서울 양천구 오목로 299      (지번) 목동 962   \n",
       "18     락희안 목동점                          서울 양천구 오목로 330 2,3층  (지번) 목동 405-285   \n",
       "19        구도커피                       서울 강서구 등촌로35길 121 1,2층  (지번) 등촌동 565-18   \n",
       "\n",
       "   category  \n",
       "0     육류,고기  \n",
       "1      게,대게  \n",
       "2     해물,생선  \n",
       "3     육류,고기  \n",
       "4     육류,고기  \n",
       "5        장어  \n",
       "6        뷔페  \n",
       "7       설렁탕  \n",
       "8     족발,보쌈  \n",
       "9     커피전문점  \n",
       "10    해물,생선  \n",
       "11      닭요리  \n",
       "12    곱창,막창  \n",
       "13       한식  \n",
       "14     초밥,롤  \n",
       "15   실내포장마차  \n",
       "16       순대  \n",
       "17       양식  \n",
       "18     중화요리  \n",
       "19    커피전문점  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23141efa-3948-49db-be28-fb187cc2af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.to_csv('rating_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8814d2cb-f413-4c5d-886c-920b7dabcee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.to_csv('rating_df_test.csv', sep=',', na_rep='NaN', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90a3e0a7-d169-431b-a5e0-65287d15a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.to_csv('rating_df_ko.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dab81034-eabb-44aa-82db-370833e4718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.to_csv('restaurant_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ccefa61-f974-48b1-a2ee-40e66c48058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.to_csv('restaurant_df_test.csv', sep=',', na_rep='NaN', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa0df348-b5a3-44ca-a526-d2345f1ddd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.to_csv('restaurant_df_ko.csv' , encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274c7adc-e4ee-4ab8-a57e-70e08123f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### 어니언 안국점\n",
      "아이랑 왔는데 친절하시고 서비스 정말 좋으시네요. 아이가 마실 딸기 요거트 시키려는데 직원분이 먼저 아이용 맛보기 샘플 무료로 제공중인데, 아이가 많이 마시는 편이 아니라면 그걸로도 양이 충분할 수 있을지 물어보셔서, 그렇다고 말씀드리며 감사히 무료 샘플 받았어요. 샘플 사이즈가 저희 아이에게 딱이었네요 ㅎㅎ 올리브 베이컨 빵이랑 앙셀 슈슈도 시켰는데 둘 .../5\n",
      "/3\n",
      "아침 일찍가면 사람 없어서 좋아요 카페메뉴 가격대가 높은편./4\n",
      "멋진 장소 친절한 직원 그러나 벌레가 많음/4\n",
      "공주밤빵 검정크런치 맛이 좋지는 않아요/1\n",
      "장소가 넓고 분위기가 좋아요. 대체로 메뉴가 맛있어요/4\n",
      "시오빵 너무맛있음/5\n",
      "커피와 빵의 맛으로 볼 때 요즘 이 만한 집이 어디 한 둘이겠는가 그러나 대체 불가한 이 곳에 꼭 가야할 이유는 이 마루에 있지않을까 종로 한복판에 왜색짙은 까페와 식당이 정체성없이 난립될 때 정통 한옥의 재해석을 그 어느곳보다 완벽히 해내 서울의 아름다움을 한층 부각시킨다. 사브작되는 앞마당과 한낮 바람도 식어 흐르는 이 마루에서 읽히는 휴식은 최고의 힐.../5\n",
      "사람 넘많아... 순환 안 돼고 정신ㄹ없음 /3\n",
      "어니언은 어느 지점이나 꽤 친절한 것 같아 좋아요 빵도 맛있고 음료도 맛있고 굳  근데 사람 너무 많음…. /4\n",
      "앙버터 맛집, 멀리까지 빵 사러 가기 힘들었는데 여기서 살 수 있어서 좋아요!! /5\n",
      "맛있어요^^ 산미 부분은 조금 개선 해야 할듯해요ㅎ/5\n",
      "빵도 넘 맛있고 직원분들이 친절해서 너무 좋음!아인슈페너 맛있다던데 담에 먹어봐야게씀 ㅎㅎ/5\n",
      "/5\n",
      "주말이라 조금 대기했지만 안내해주시는 직원분들이 친절하시고 자리나면 바로바로 배치해주셔서 좋았어요~ 빵도 맛있었구요!! 커피맛은 약간 아쉽네요^^;;/4\n",
      "커피가 너무 맛이 없음. 산미있대서 기대했는데 산미도 없고 그렇다고 고소한 맛도 없이 텁텁 + 밍밍. 빵은 그럭저럭인데 전체적으로 돈이 아깝다 싶을 정도로 맛이 없음. 분위기는 좋음. 그냥 참새 구경하면서 한옥 배경으로 사진 찍기 좋은 곳. /2\n",
      "/5\n",
      "금요일 한낮 카페가 붐비는데도 직원분들이 한명한명 정말 친절하고 상냥하고 활기가득이었어요 응대받는 손님이 기분이 좋아질 정도였음! 팡도르는 신세계였고 슈가파우더 안 빵 자체가 담백쫄깃하니 정말 맛있었어요. 다른 빵들도 부가 재료보다 빵 맛이 뛰어났고, 버터 가득이어도 부담스럽거나 느끼하지 않았어요.  초코케이크는 꾸덕해보이는 것에 비해 설탕대신 카카오를 많.../5\n",
      "인테리어만으로 만족 넘예쁨/5\n",
      "/4\n",
      "참새가 제 빵 쳐먹고 튀었어요 그래도 직원분들은 착해요 응대 잘해주심 그래도 참새가 너무 싫어서 1점 줘야겠어영/1\n",
      "앗! 죄송합니다. 오늘 오후 쯤에 공주밤빵이랑 앙버터를 골랐었는데 다른 분 꺼랑 바꼈네요. 다음부턴 제대로 확인하겠습니다./5\n",
      "가성비는 안 좋지만 다른 인스타 핫플에 비해 자리가 널찍해서 덜 시끄러워요/3\n",
      "평일에 갔는데 사람도 많지 않고 좋았어요/5\n",
      "/3\n",
      "빵은 맛있지만 커피가 너무 맛없어요 밍밍하고 산미가 강하다 못해 셔요ㅠ 소금빵이랑 인절미팡도르 맛있어요 공주밤빵은 생각보단 그냥 그래용 분위기체고 다른 빵도 먹어보고싶어요 빵 가격 사악하다고 하는데 전 솔직히 잘 모르겠어요 나폴레옹보다 싼듯? 스콘 4500원은 비싼듯하지만 크기가 큼/4\n",
      "성수점이랑은 또 다른분위기.. 성수점때는 콧대높은 분위기에 특별함을 몰랐는데 안국점은 바쁜데도 직원들 친절하구 활기있었어요~ 평일 저녁에 갔어요. 디카페인가능해서 저녁에도 좋았고 음료받을때 이름으로 불러줬어요~/5\n",
      "직원들 편안하게 친절하시고, 맛있어요 예뻐요/5\n",
      "직원관리 좀 하셔야겠네요 어떤직원은 말투부터 불친절하더라구요  커피주문하고 나니까 기분 드러워졌어요 /2\n",
      "많이 변했어요..ㅠ 가오픈때부터 갔던 어니언 안국은 사라졌습니다... 마루에 앉아서 먹는 그 감성때문에 자주 방문했었는데, 마루엔 빵가루가 날리고 커피도 쏟아져있고... 실망이 커서 돌아왔습니다../2\n",
      "/5\n",
      "멀리서 바라볼 때 아름다움./3\n",
      "/3\n",
      "가격대가 좀 있는데 이정도면 괜찮은거같아요/4\n",
      "커피는 아직 안먹어봤지만 샌드위치 넘 좋아요 추천 /5\n",
      "공간을 방문하는 햇살 버금가는 맛 정겨운 소리 발걸음 도심 속 휴식/5\n",
      "앙버터는 팥이 씹혀서 개인적으로 맛있게 먹었는데... 아메리카노는 진짜 심하게 맛없음. 물 잔뜩 탄 맛... 차라리 플랫화이트가 나았음. 입구에서 사진만 찍기 좋은 곳. /1\n",
      "서울사람 다 여기 모인거같음 진짜 졸라붐빔 갈때마다 ㅡㅡ 시끄럽구로  빵은 매우 맛있음 아보카도명란바게트랑 까만크림치즈소보로 ? 굿 /4\n",
      "공간 디자인 하나만으로도 가봐야 하는 곳. 조금 덜 붐비는 시간에 가면 좋아요!/5\n",
      "분위기는 좋으나 가격대가 있는편/4\n",
      "커피는 4점 주고싶음 인테리어는 5점 주고싶음 그치만 관리가 안돼서 안타까움  화장실도 내부도 급속도로 낡고 지저분해져서 안타까움;; 이렇게까지 관리가 안될 수가 있나 싶을 정도? /2\n",
      "그냥 그래요. 여기 갈 바엔 다른 곳을 가겠어요. /2\n",
      "빵이...사람들 줄서는길 진열대 맨 아래에 두다니요..진열빵 위에서 수다떠는 사람들도 이해안가지만 진열대기중인 빵을 사람들 걷는 길바닥 아래에 셋팅하다니..그냥 제빵실안에 두면 안되는거였나요..그거 가지러 왔다갔다 하는게 그렇게 귀찮으시면 빵을 팔지 마셔야죠../2\n",
      "/5\n",
      "빵이 정말 평-범 그 자체!!ㅎㅎ 음료도 아주아주 평범 그자체ㅎㅎ 서비스는 아주아주 친절함  대신 한옥이 예쁘고 이게 다 하는 곳 날씨 좋을때 오픈된 마루에 앉아서  커피홀짝 빵냠하기에 최적의 인테리어를 갖췄음ㅎㅎ  빵커피맛집은 아니고 분위기맛집  언제가도 사람 너무 많지만 지리적으로나 규모로나 그럴 수 밖에 없음ㅠ/4\n",
      "객관적으로 너무 맛이 없습니다. 가게 직원 친절하고, 인테리어 예쁘고, 넓습니다. 단지 단점은 하나-빵 맛이 없어요.  나쁜가게는 절대 아닙니다. 그냥 맛이 없어요./1\n",
      "ㅠㅜㅜ팡도르가 그렇게 맛있나요ㅠㅠ? 모르겠ㄱ던데ㅠㅜㅜ아님 제가 팡도르를 너무 기대한 탓일까요ㅠㅠ? 안에 크림이나 뭐가 잇을 줄 알앗는데ㅠㅜㅜ 네버ㅠㅠㅠ 그냥 슈가파우더만 위에 가득 뿌려지기만 한 팡도르ㅠㅠㅠ/3\n",
      "맛난 디저트빵 맛난 커피, 바글바글한 사람들/3\n",
      "/3\n",
      "예쁘고 맛있고 날 좋은날 가기에 좋아요ㅜㅜ...!!!~/5\n",
      "너무 이쁜데 사람이 엄청 많아서 자리가 없어요 ㅠㅠ/4\n",
      "/3\n",
      "아메리카노 2000원 행사하고 있었어요 완전 저렴/5\n",
      "감성을 위해서 너무 많은 걸 포기해야 함 근데 그럴 가치가 있긴 해요 카페가 정말 예쁘긴 합니다...만.... 음 사람 많이 안몰릴 시간에 가세요 /3\n",
      "인테리어는 너무 예쁨 그러나 1. 테이블이 더러워 물티슈로 닦았는데 정말 더러움.  2. 이 시국에 베이커리류를 쇼케이스 없이 진열함.   성수점은 어떤지 몰라도 안국점은 매장 관리가 안되어 있음. /1\n",
      "알바 느려터짐/1\n",
      "여기유명하던데.. 빵이 엄청 일찍 나가서.. 여기 굴뚝빵 먹어보기가 힘들어요 ㅜ/3\n",
      "카페모카에서 커피와 초콜릿 맛 이외의 신맛이 났어요... 카페모카도 이렇게 맛없을 수 있구나를 배우고 갑니다^^/1\n",
      "장소는 이쁘나..빵과 음료는 그냥 그럼. 빵조각이 있다면 참새를 가까이서 볼 수 있다./4\n",
      "빵 맛있다./5\n",
      "어니언 한장요약 ㅋ/1\n",
      "한번 와봤으니 되었오./3\n",
      "트러플맘모스 빵 맛있음 음료는 양이 종이컵수준 비쌈 공간만 이쁘고좋음/3\n",
      "이렇게 큰 가게를 뭘 믿고 차렸는지 모르겠다. /2\n",
      "커피 맛있고 공간도 예쁜데 베이커리 최악 ㅠㅠ 3개천원하는 빵보다 맛없음 뻑뻑하고/3\n",
      "분위기는 좋은데 바리스타들도 멋지던데 왜 불친절하지? 커피맛이 좀 아쉽네 빵은 종류만 많지 별로 먹고 싶은것이 없네 아쉽다/2\n",
      "다들 이게 얼마로 보이시나여 바로 17000원 입니다 인스타 감성 찾는다해도 가지마세요  @ 인테리어— 들어가자마자 이거 버리는건가?; 싶은 녹 슨 의자와 테이블이 즐비해 있습니다 ( 잠깐 앉았는데 엉덩이 시리고 불편함 이게 뭔가싶은 ,,,)  그러면 안으로 들어가면 되지않냐? _ 자리가 없습니다 진짜 사람들 빽빽해여 ,, 인생샷 찍기에는 채광이 안좋아서 .../1\n",
      "인테리어는 좋음 불친절, 맛 없음 바라보는 사람이 그렇게 많은데  필터커피 내리는 중간중간 핸드폰하는 바리스타../1\n",
      "가격이 사악함  조금 씨끄러움/4\n",
      "분위기 말곤 내세울 게 없다./3\n",
      "/3\n",
      "평이 안좋아서 걱정했는데 생각보다 맛도 괜찮고 분위기도 굳./5\n",
      "/2\n",
      "진짜 분위기말고 내세울게없다. 저번에도 커피 드럽게 맛없더니 이번엔 커피는 믿고 거르고 쑥차 셨는데  저런식으로해서 비싸게팔고 오래장사하고 싶으면 커피원두를 바꾸던지 제대로 교육을 시키던지 해야할듯../1\n",
      "이젠 굳이 찾아갈 필욘 없는/2\n",
      "생각했던것보다 아인슈페너가 맛있었고, 자리도 잘 치워주셨다.. 번호표나 진동벨이 있었음 좋겠다 이름 부를때 너무 안들려서ㅠㅠ/3\n",
      "난 성수보다 여기가 더 좋더라 사람많아서 항상 밖에 앉음..../3\n",
      "빵은 퍽퍽하고 커피는 평범, 사람도 넘 많음/2\n",
      "/5\n",
      "/5\n",
      "사진 찍기 위한 사람들이 아주 많이 모인 곳./2\n",
      "다신 가고싶지않음/1\n",
      "인절미 팡도르도 맛있고 커피도 맛있고 인테리어도 이쁘지만 사람이 너무 많아서 매장 관리가 제대로 안 되어서 아쉽다ㅠㅠ 테이블이 너무 더러워,, 카페가 너무 유명하고 좌석 간 거리가 좁다보니 대화 나누기에는 적당하지 않은 듯,, 사진 찍는 사람들이 너무 많아 내 얼굴도 거기에 같이 나올 듯...ㅎ̌̈/3\n",
      "자리 청소 좀 해 주지. 앞 사람 먹은 빵 부스러기들이 그대로.. 아, 드러../2\n",
      "/5\n",
      "사람 쏘 매니/3\n",
      "/3\n",
      "이정도 하는 빵집은 동네에도 있는듯.../1\n",
      "힙힙힙/5\n",
      "스콘, 빵은 평범 하나 안에 들어가는 팥 덕분에 먹을만 했고, 앙버터 스콘보다 그냥 앙버터 빵이 더 맛있어요. 유명세 만큼 맛집은 아닌것 같고 분위기가 진짜 좋은 곳 같아요!/4\n",
      "분위기가 참 좋음.. 밤엔 멋있음.  다만.. 춥고.. 커피나 빵은 보통이예요./3\n",
      "너무 추워요/1\n",
      "주말엔 사람이 많다 평일도 사람이 많다/1\n",
      "커피 괜찮고 외관 괜찮은데 내부는 다닥다닥 붙어있는 밥집만 못해요. 전면이 유리인데 유리창 틈새로 한기가 엄청 들어와서 냉골... 히터도 소용없는 냉골../1\n",
      "분위기는 참 좋았으나 의자 엄청 딱딱하고 불편합니다 방도 다과상은 낮고 더불편할듯!! 커피와 빵가격 맛 다른곳에 밀리진 않습니다 계산대와 커피 회전율이 너무 좋지 않아 곳곳의 직원들이 한가한데도  손님들은 대기중~~~안내도 부족~~~ 물티슈도 빵샀는데 기본 제공 안하면서 가져가려니 시킨 음료 나올때 준다며 도끼눈!!!  결국 시킨 트레이에 없었음 가장 문제.../1\n",
      "Einspanner, 초코라 and 팡도르. 9시처럼 일찍와./3\n",
      "카푸치노가 미지근하네요.  옆건물이 바로 주방이있는 건지 왼쪽 홀에는 생선비린내가 좀 나네요.  빵맛은 괜찮은데 사람들이 분주하게 오가는중에 청결이 아쉬웠어요.  한국방문하는 관광객이 많은 건 좋지만 그래서인지 아침 9시에도 자리 잡기가 힘드네요. /2\n",
      "워낙 많이 들어서 왔는데 빵진열도 사람들 다니는곳에 오픈한채로 두고 고르게 되어있네요. 사람들 이야기 하면서 고르고 먼지.침 다 떨어지고 빵 고르고 나서도 음료주문하느라 20분 넘게 기다림. 최악은 메뉴판이 다 영어로 되어있음. 한옥에 영어간판 단것까지는 그렇다쳐도 왠 영어일색 메뉴판인가요? 한국에서 한글메뉴판 쓰면 뭐 격이 떨어지나요? 한국적인테리어에 그.../1\n",
      "이쁘고 다 좋은데 주문이 너무너무너무너무 오래걸림. 사람이 그리 많은데 주문 받는사람이 한명이며 그 사람이 느릿느릿 빵 포장까지하며 주문 받느라 주문만 몇십분 . 게다가 좌석은 멀리 있는데 진동벨을 주지 않아 주문한 것 받는것도 힘듦. 외국인도 많던데 주문 받는 알바 좀 늘렸으면. 성수 어니언도 주문이 완전 느렸는데 느린 주문이 정책인건지 ㅡㅡ/1\n",
      "자리잡는데 10분, 줄서서 주문하는데 20분. 주말에 가니 사람이 많네요. 팡도르 맛있었어요/4\n",
      "장소는 걍 대충 만들고, 사람은 많은데 응대준비 부족하고 빵 비싸고.정신없고.. 뭐하러 가냐여기/1\n",
      "비싸기만 함/1\n",
      "태어나서 이렇게 맛없는 라떼 첨먹어봐요 /1\n",
      "커피: 맛있음 빵 : 맛있는편.  분위기: 한옥 인테리어. 넓은 하늘. 좋음  단점: 역시 위생. 테이블 아래 놓여진 바닥 가까이 빵들.                      자리없음. /3\n",
      "인간적으로 빵값 너무 비싸다. 커피는 드럽게 맛이 없으면서../1\n",
      "/3\n",
      "건물과 인테리어가 전부/1\n",
      "분워기만 조금 좋음 마루는 조금 아니 조금 많이 지져ㅂ/1\n",
      "분위기만 좋은걸로... 커피가 진짜 맛없... /1\n",
      "/2\n",
      "/1\n",
      "블로그만 보고 잔뜩 기대하고 방문했는데 커피맛이나 빵맛에 실망했다기보다 내부가 지저분해서 실망하고 왔어요 평일에 자리가 거의 만석이었는데 좌석정리하는 직원은 한 명도 보이지 않았구요 방석에 앉긴 했지만 사방에 머리카락이 널려있고 반납하지 않은 음식물 쟁반 계속 방치되어 있고 화장실엔 화장지가 칸칸마다 없어요 음식도 중요하지만 카페시설관리도 신경써 주시면 좋.../1\n",
      "한옥에 하얀 자갈밭! 인테리어는 멋있음 베이커리는 전반적으로 별로 대표빵인 팡도르를 포함하여 스콘, 앙버터도 그냥 그랬음 그리고 주문 너무오래 걸림 주문받는사람을 늘리던지 해야 할 듯ㅠ/2\n",
      "오래된 한옥집 대청마루에 앉아서 하늘구경 사람구경 잘했음.  커피 주문하는데 메뉴판을 크게 비치해서 멀리서도 볼 수 있게 해붰으면 함.  주문하는데 너무 오래걸림.  분위기랑 인테리어는 굿. 빵이랑 음료는 보통.  주문 및 계산은 낙제점./3\n",
      "한옥느낌만좋음//직원서비스최악+손님은넘쳐나는데 직원들손느림(커피제조속도심각함 교육을안하는듯?)//커피맛없음//앙스콘먹었는데 간이안맞음.. //여기가왜인기있는베이커리카페인지모르겠네요..단지한옥느낌보려고가시는건상관없는데맛이중요하신분이라면비추합니다*^^/1\n",
      "잔짜 커피나 빵맛을 위해 찾는거라면 개인적으로 비추. 사람구경 하고싶으면 추천 ^^ 근데 카페는 참 멋지긴 하다../3\n",
      "커피 빵 맛있는데 손님에 대한 배려가 전혀없음 심각 /2\n",
      "사람이 정말 너무 많아요 그래서 직원분들의 서비스가 많이 떨어지는데 아쉽네요. 빵 포장 막해줘서 되게 별로였어요./2\n",
      "/3\n",
      "오픈한지 얼마 되지 않았지만 평일 낮에도 사람들은 너무 꽉찼고, 빵가격은 비싼게 흠이지만 도심속 이런 풍경속에서 차 한잔 할수 있다는 것이 감사하다. /4\n",
      "사대문 안의 옛 포도청이었던 한옥 안에서 마시는 커피. 오픈한 지 얼마 안되었는데도 외국인들 바글바글. 어니언 커피도 옛날에 비해 엄청 맛있어졌다./5\n",
      "no review in crawling\n",
      "#### 황생가칼국수\n",
      "저는 칼국수보다 만두가 맛있더라고요. 상세 평가리뷰 블로그에 글써봤습니다.  아래링크에 구경오세요~ https://vo.la/gD2cM/4\n",
      "11시44분 칼국수 2개 주문했는데 정확히 12시15분에 나옴...점심시간이라고해도 30분이나 기다려 먹을만큼의 퀄리티는 아니었어요~김치맛있다고 하던데 명*칼국수 김치맛과 비슷~가격도 9천원이니 싼편도 아니고...무엇보다 너무 늦는 음식에 짜증이나서 콜벨을 3번이나 눌렀으나 그 많은 직원이 대답조차 없더군요~30분만에 나온 음식 갖다주며 직원에게 30분만에.../1\n",
      "/5\n",
      "원래 콩국수 못 먹는데 30년만에 처음으로 먹어봤습니다. 이 맛있는걸 왜 여태껏 안먹었나 싶네요/5\n",
      "만두국과 김치 맛있는곳!/5\n",
      "특별한 맛집은 아니에요, 평범 콩국수는 담백했고 만두국은 맑은 국물인데 간간해요 백김치는 좀 더 새콤해도 맛있을거같고 빨간김치는 좀 달아요, /3\n",
      "칼국수랑 콩국수 같이 시켰는데 둘다 맛있네요 ㅎㅎ 근데 칼국수가 정말 맛있어요 담백하고 삼삼해요./5\n",
      "/4\n",
      "오래 오래 장사해주세요. 칼국수+김치 최고의 조합!/5\n",
      "김치 짱맛 만두국?이랑 칼국수 하나씩 해서 노나드셈 슴슴하니 기분 좋아지는 맛입니다 근데 좀 쌀쌀할 때 추천해요 그러면 더 마음이 든든해지거든요/5\n",
      "사골 베이스에 파와 호박, 버섯으로 맛을 낸 깔끔한 칼국수입니다.  공간은 테이블 간격이 여유있고 쾌적했습니다. 식당 앞에서 낮잠을 자는 고양이를 보고 갈 수도 있어요. 직원분들도 친절하셨습니다./5\n",
      "직원분들 친절하심 옆자리서 김치 맛있다고 호들갑떨음 만두국은 양이 아쉬운듯하면서 적당하고 칼국수도 괜찬음/5\n",
      "국수 만두 짱입니다,,, 적당히 슴슴한 것이 마이스똴/4\n",
      "/4\n",
      "만두국 김치 다 맛있는데  홀 친절도는 신경 쓰셔야 할듯  음식 틱틱 놓고 국자는 멀리서 받으라하네요 /4\n",
      "음.... 겉저리와 백김치에 칼국수가 사이드로 나온 느낌이랄까?? 만두국은 괜찮았네요 담백한 맛을 좋아하는 분들에게는 딱일 듯 싶네요 /3\n",
      "사람 없을때도 다닥다닥 붙여앉혀서 별로/1\n",
      "이야~ 2년전 1년전 오늘 갔을때 맛이 하나같이 다 다른데 하나확실한건 점점 다운그레이드. 사진은 색이 뿌옇게보이는데 실제로는 그냥 거의맑은물수준....아니 점점 관리를포기하는건지 원가절감하는건진 모르겠는데 이젠 더이상 돈주고사먹을맛이아니네여.패스/1\n",
      "난 대부분의 만두는 다 맛있다고 먹지만 요기 만두귝 찐맛 늠나 맛이쏭/5\n",
      "/5\n",
      "운이 좋아 웨이팅 없이 먹었는데, 양도 많고 푸짐하고 배도 든든하고 좋았다. /4\n",
      "만두국 맑은 국물 너무 좋고 진짜 맛있었어요! 솔직히 칼국수는 쫄깃하지 않아서 조금 실망했지만... 손만두는 진짜 맛있어요. 역시 미쉐린 가이드 맛집 입니다! /5\n",
      "손님이 굉장히 많아 기다려야 하는 곳입니다. 언제 또 오겠나 싶어서 만두에 모듬전에 칼국수까지 주문했는데 칼국수 한 그릇을 둘이 먹게 나눠주셔서 좋았습니다. 만두랑 칼국수가 맛있었구요, 모듬전은 메뉴에선 육전, 동태전, 고추전이 나온다고 되어있는데 육전이 아니고 동그랑땡이라 살짝 실망했어요./4\n",
      "저도 칼국수보다 만두 추천이요 ㅋㅋ/4\n",
      "칼국수도 맛있고 김치도 맛있고~~♡/5\n",
      "정말 맛있게 먹음 종업원 분들 정말 친절하심/5\n",
      "최고의 맛 감사합니다/5\n",
      "칼국수와 만두굿/4\n",
      "가야는이유 : 2017년부터 빕구르망에 선정 안가는이유 : 대기가 긴  너무 진한 육수가 아니라서 좋고 간도 마음에 드는 국물은 칼국수가 더 좋았고 면보다 만두가 더 좋았음 겉절이는 좋았지만 백김치는 너무 달았음 만두를 대부분 따로 시켜서인지 양이 아주 많진 않음 주말 1시반 도착 30분 정도 대기 가족단위 손님이 많아 한번에 많이 빠지는편/4\n",
      "국물이 깔끔한게 아주 좋았습니다. 만두도 되게 부드러워서 좋았어요. 김치는 그냥 그랬고 백김치는 많이 아쉬웠어요. 매장입구는 턱이 두개가 있습니다. 휠체어는 도움이 필요할거예요./3\n",
      "맛있어요/4\n",
      "삼삼한맛/4\n",
      "국물이 맛있음. 후추 뿌려드세요/5\n",
      "/4\n",
      "추운날 먹었더니 뜨뜻한게 너무 좋아요 ㅎㅎㅎ 막 너무 맛있다 보단 슴슴하고 좋아요 :) 이정도면 저렴하고 양도 많고 맛있네요/5\n",
      "/5\n",
      "추운날에 먹으니 더 맛이 좋은 듯~ 맛나게 먹었네요~/4\n",
      "존맛/5\n",
      "절대 비추. 그냥 명동교자 가세요./1\n",
      "고기 육수. 부드러운 고기. 씹는 맛 버섯, 애호박. 매콤 상콤 김치 그리고 마무리는 백김치!!! 엄청 맛나네요!!!/5\n",
      ".칼국수:  맛이 없진 않지만 사골육수는 흐리고 MSG맛이 강하게 느껴짐. .왕만두: 잘하는 분식집이 훨씬 나을듯. .겉절이 김치: 자극적이지 않은 맛이라 호불호가 갈릴 수 있지만 괜찮음.   줄서서 먹을 맛집은 아님./2\n",
      "맛있고 양도 적지 않습니다./5\n",
      "가격이 좀 있지만 그 만큼 맛있어요!/5\n",
      "사골칼국수인데도 담백하고 맛있어요. 양도 엄청 많습니다. 만두는 식감이 부드럽고 맛있어요. 식으면 맛이 반감되니 따듯할 때 드세요./5\n",
      "국물이 맛/5\n",
      "조미료맛 많이 나는 칼국수/2\n",
      "맛있어요 국물이 좀 사골국?같은 맛이 좀 나고 면이 얇은데 은근히 많아요. (여자입장) 만두국과 같이 시켰는데 만두국에는 김이 들어가는데 칼국수에는 안들어가더라구요ㅋㅋ 신기 물어보니 원래그런거 맞다고 합니다, 여튼 다진고기가 아닌 실제고기도 들어있고 고기맛이 잘나는 칼국수라고 생각하시면 됩니다. 9천원인 가격의 압박은 있죠 칼국수 인데 ㅋㅋㅋㅋ 그래도 몸 .../4\n",
      "불친절해요. 유명한 맛집이라고 하는데 사실 그렇게 맛있는지도 잘 모르겠음/1\n",
      "지림/5\n",
      "근방에서 가장 부담 없이 가기 좋은 곳 같아요. 만두 맛있습니다./5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-52b5d5e0db76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-52b5d5e0db76>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mlists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'종로구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'중구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'용산구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'성동구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'광진구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'동대문구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'중랑구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'성북구 맛집'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'강북구 맛집'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-52b5d5e0db76>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(place)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# 검색된 첫 페이지 장소 목록 크롤링하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mcrawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0msearch_area\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-52b5d5e0db76>\u001b[0m in \u001b[0;36mcrawling\u001b[1;34m(place, place_lists)\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_link_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'다음'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 \u001b[0mextract_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 리뷰 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mElementNotInteractableException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no review in crawling\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-52b5d5e0db76>\u001b[0m in \u001b[0;36mextract_review\u001b[1;34m(place_name)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_url_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             return self.request_encode_url(\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"?\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     def request_encode_body(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             )\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "##############################################################  ############\n",
    "##################### variable related selenium ##########################\n",
    "##########################################################################\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "# chromedriver_path = \"chromedriver\"\n",
    "# driver = webdriver.Chrome(os.path.join(os.getcwd(), chromedriver_path), options=options)  # chromedriver 열기\n",
    "\n",
    "rating_df = pd.DataFrame() # 리뷰 저장 데이터 프레임\n",
    "restaurant_df = pd.DataFrame() #음식점 정보 저장\n",
    "\n",
    "def main():\n",
    "    global driver, load_wb, review_num\n",
    "\n",
    "    driver.implicitly_wait(4)  # 렌더링 될때까지 기다린다 4초\n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "\n",
    "    # 검색할 목록\n",
    "    lists = ['종로구 맛집', '중구 맛집', '용산구 맛집', '성동구 맛집', '광진구 맛집', '동대문구 맛집', '중랑구 맛집', '성북구 맛집', '강북구 맛집']\n",
    "    for list in lists:\n",
    "        search(list)\n",
    "        \n",
    "    driver.quit()\n",
    "    print(\"finish\")\n",
    "\n",
    "\n",
    "def search(place):\n",
    "    global driver\n",
    "\n",
    "    search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')  # 검색 창\n",
    "    search_area.send_keys(place)  # 검색어 입력\n",
    "    driver.find_element_by_xpath('//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER) # 더보기\n",
    "    sleep(1)\n",
    "\n",
    "    # 검색된 정보가 있는 경우에만 탐색\n",
    "    # 1번 페이지 place list 읽기\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem') # 검색된 장소 목록\n",
    "\n",
    "    # 검색된 첫 페이지 장소 목록 크롤링하기\n",
    "    crawling(place, place_lists)\n",
    "    search_area.clear()\n",
    "\n",
    "    # 우선 더보기 클릭해서 2페이지\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER)\n",
    "        sleep(1)\n",
    "\n",
    "        # 2~ 5페이지 읽기\n",
    "        for i in range(2, 6):\n",
    "            # 페이지 넘기기\n",
    "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "            driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "            sleep(1)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            place_lists = soup.select('.placelist > .PlaceItem') # 장소 목록 list\n",
    "\n",
    "            crawling(place, place_lists)\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        print('not found')\n",
    "    finally:\n",
    "        search_area.clear()\n",
    "\n",
    "\n",
    "def crawling(place, place_lists):\n",
    "    \"\"\"\n",
    "    페이지 목록을 받아서 크롤링 하는 함수\n",
    "    :param place: 리뷰 정보 찾을 장소이름\n",
    "    \"\"\"\n",
    "\n",
    "    while_flag = False\n",
    "    for i, place in enumerate(place_lists):\n",
    "        # 광고에 따라서 index 조정해야함\n",
    "        #if i >= 3:\n",
    "         #   i += 1\n",
    "\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text  # place name\n",
    "        place_address = place.select('.info_item > .addr > p')[0].text  # place address\n",
    "        place_detail = place.select('.info_item > .contact> .moreview')[0].get('href') # place detail\n",
    "\n",
    "        driver.execute_script('window.open(\"about:blank\", \"_blank\");')\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        driver.get(place_detail) # 상세정보 탭으로 변환\n",
    "        sleep(1)\n",
    "\n",
    "#         detail_page_xpath = '//*[@id=\"info.search.place.list\"]/li[' + str(i + 1) + ']/div[5]/div[4]/a[1]'\n",
    "#         driver.find_element_by_xpath(detail_page_xpath).send_keys(Keys.ENTER)\n",
    "#         driver.switch_to.window(driver.window_handles[-1])  \n",
    "        \n",
    "        print('####', place_name)\n",
    "\n",
    "        # 첫 페이지\n",
    "        extract_review(place_name) # 리뷰 추출\n",
    "\n",
    "        # 2-5 페이지\n",
    "        idx = 3\n",
    "        try:\n",
    "            page_num = len(driver.find_elements_by_class_name('link_page')) # 페이지 수 찾기\n",
    "            \n",
    "            for i in range(page_num-1):\n",
    "                # css selector를 이용해 페이지 버튼 누르기\n",
    "                driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "                extract_review(place_name)\n",
    "                idx += 1\n",
    "            driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 5페이지가 넘는 경우 다음 버튼 누르기\n",
    "            sleep(1)\n",
    "            extract_review(place_name) # 리뷰 추출\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            print(\"no review in crawling\")\n",
    "\n",
    "        # 그 이후 페이지\n",
    "        while True:\n",
    "            idx = 4\n",
    "            try:\n",
    "                page_num = len(driver.find_elements_by_class_name('link_page')) #페이지 수 찾기\n",
    "                \n",
    "                for i in range(page_num-1):\n",
    "                    driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                    sleep(1)\n",
    "                    extract_review(place_name)\n",
    "                    idx += 1\n",
    "                driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\n",
    "                sleep(1)\n",
    "                extract_review(place_name) # 리뷰 추출\n",
    "            except (NoSuchElementException, ElementNotInteractableException):\n",
    "                print(\"no review in crawling\")\n",
    "                break\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])  # 검색 탭으로 전환\n",
    "\n",
    "\n",
    "def extract_review(place_name):\n",
    "    global driver\n",
    "\n",
    "    ret = True\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 첫 페이지 리뷰 목록 찾기\n",
    "    review_lists = soup.select('.list_evaluation > li')\n",
    "\n",
    "    # 리뷰가 있는 경우\n",
    "    if len(review_lists) != 0:\n",
    "        for i, review in enumerate(review_lists):\n",
    "            comment = review.select('.txt_comment > span') # 리뷰\n",
    "            rating = review.select('.grade_star > em') # 별점\n",
    "\n",
    "            \n",
    "            val = ''\n",
    "            if len(comment) != 0:\n",
    "                if len(rating) != 0:\n",
    "                    val = comment[0].text + '/' + rating[0].text.replace('점', '')\n",
    "                else:\n",
    "                    val = comment[0].text + '/0'\n",
    "                print(val)\n",
    "\n",
    "    else:\n",
    "        print('no review in extract')\n",
    "        ret = False\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246edc65-5ea0-492d-8594-5177365455c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
