{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013d25a-5160-4e23-9409-932a79de2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021.08.12\n",
    "# kakaoMap_crawling_2.ipynb 수정버전\n",
    "# 수정사항 : 지역구 맛집 검색 및 CSV 저장 자동화 수정, 데이터 변수 종류 및 오류 수정(리뷰 코드, 가게 코드 추가, 비어있는 값은 None값으로 통일)\n",
    "# 추가사항 : 데이터 저장 방식 변경(클래스 추가)\n",
    "\n",
    "# 문제점 : DB 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a34a04b1-d083-48ed-a5db-3f31c8fb9027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 0 : 종로구 맛집\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(1062, \"Duplicate entry 'STORE_JRO0001' for key 'PRIMARY'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c97100c514a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;31m#### 메인 ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c97100c514a5>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mlocal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_local_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mcreate_csv_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c97100c514a5>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(place, local)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# 검색된 첫 페이지 장소 목록 크롤링하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mcrawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# 전체 페이지\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c97100c514a5>\u001b[0m in \u001b[0;36mcrawling\u001b[1;34m(place, local, place_lists)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;31m#### 데이터 베이스 저장 #####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_insertCrawlingData_STORE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_local\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_category\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c97100c514a5>\u001b[0m in \u001b[0;36mdb_insertCrawlingData_STORE\u001b[1;34m(self, store_code, place_name, place_address, place_local, place_category)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"INSERT INTO STORE (STORE_CODE, STORE_NAME, ADDRESS, LOCAL_CODE, CATRGORY_CODE) VALUES( %s, %s, %s, %s, %s )\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstore_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_local\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace_category\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"surrogateescape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_status\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m             \u001b[0mfirst_packet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_packet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ok_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    719\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbuffered_active\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbuffered_active\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m             \u001b[0mpacket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpacket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\protocol.py\u001b[0m in \u001b[0;36mraise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errno =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_mysql_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pymysql\\err.py\u001b[0m in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merrorclass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0merrorclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInternalError\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrorclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m: (1062, \"Duplicate entry 'STORE_JRO0001' for key 'PRIMARY'\")"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pymysql as my\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "##########################################################################\n",
    "##################### variable related selenium ##########################\n",
    "##########################################################################\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "\n",
    "\n",
    "\n",
    "##### 가게 정보를 담는 클레스\n",
    "class STORE_Info:\n",
    "    place_code = ''\n",
    "    place_name = ''\n",
    "    place_address = ''\n",
    "    place_local  = ''\n",
    "    place_category  = ''\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, store_code = None, place_name = None, place_address = None, place_local = None, place_category = None):\n",
    "        self.store_code = store_code\n",
    "        self.place_name =  place_name\n",
    "        self.place_address = place_address\n",
    "        self.place_local  = place_local\n",
    "        self.place_category  = place_category\n",
    "        \n",
    "    # 데이터 확인\n",
    "    def data_check(self):\n",
    "        print('가게코드 : %s, 가계명 : %s, 주소 : %s, 지역 : %s, 종류 : %s' %(self.store_code, self.place_name, self.place_address, \n",
    "                                                                 self.place_local, self.place_category))\n",
    "        \n",
    "        \n",
    "##### 리뷰 정보를 담는 클레스\n",
    "class REVIEW_Info:\n",
    "    review_code = ''\n",
    "    place_code = ''\n",
    "    comment = ''\n",
    "    rating = ''\n",
    "    user_id  = ''\n",
    "    timestamp  = ''\n",
    "\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, review_code=None, store_code =None ,comment = None, rating = None, user_id = None, timestamp = None):\n",
    "        self.review_code = review_code\n",
    "        self.store_code = store_code\n",
    "        self.comment =  comment\n",
    "        self.rating = rating\n",
    "        self.user_id  = user_id\n",
    "        self.timestamp  = timestamp \n",
    "\n",
    "    # 데이터 확인\n",
    "    def data_check(self):\n",
    "        print('리뷰코드 : %s, 가게코드 : %s, ID : %s, 리뷰 : %s, 평점 : %s, 날짜 : %s' %(self.review_code, self.store_code, \n",
    "                                                                           self.user_id,self.comment, self.rating, self.timestamp))\n",
    "\n",
    "        \n",
    "### DB 다루는 클래스\n",
    "class DBHelper:\n",
    "    '''\n",
    "    맴버변수 : 커넥션 \n",
    "    '''\n",
    "    conn = None\n",
    "    '''\n",
    "    생성자\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.db_init()\n",
    "    '''\n",
    "    맴버 함수\n",
    "    '''\n",
    "    def db_init(self):\n",
    "        self.conn = my.connect(\n",
    "                        host='3.34.111.86',\n",
    "                        user='root',\n",
    "                        password='123456',\n",
    "                        db='project_db',\n",
    "                        charset='utf8',\n",
    "                        cursorclass=my.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "    def db_free(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            \n",
    "    def db_selectKeyword_STORE(self):\n",
    "        # 커서 오픈\n",
    "        # with => 닫기를 처리를 자동으로 처리해준다 => I/O 많이 사용\n",
    "        rows = None\n",
    "        with self.conn.cursor() as cursor:\n",
    "            sql  = \"select * from STORE;\"\n",
    "            cursor.execute(sql)\n",
    "            rows = cursor.fetchall()\n",
    "        return rows           \n",
    "    \n",
    "    def db_selectKeyword_REVIEW(self):\n",
    "        # 커서 오픈\n",
    "        # with => 닫기를 처리를 자동으로 처리해준다 => I/O 많이 사용\n",
    "        rows = None\n",
    "        with self.conn.cursor() as cursor:\n",
    "            sql  = \"select * from REVIEW;\"\n",
    "            cursor.execute(sql)\n",
    "            rows = cursor.fetchall()\n",
    "        return rows      \n",
    "\n",
    "    def db_insertCrawlingData_STORE(self, store_code, place_name, place_address, place_local, place_category):\n",
    "        with self.conn.cursor() as cursor:\n",
    "            sql = \"INSERT INTO STORE (STORE_CODE, STORE_NAME, ADDRESS, LOCAL_CODE, CATRGORY_CODE) VALUES( %s, %s, %s, %s, %s )\"\n",
    "            cursor.execute(sql, (store_code, place_name, place_address, place_local, place_category)) \n",
    "        self.conn.commit()\n",
    "        \n",
    "    \n",
    "    def db_insertCrawlingData_REVIEW(self, review_code, store_code, user_id, rating, comment, timestamp):\n",
    "        with self.conn.cursor() as cursor:\n",
    "            sql = \"INSERT INTO REVIEW (REVIEW_CODE, STORE_CODE,  USER_ID, SCORE, REVIEW, UPLOAD_DATE) VALUES( %s, %s, %s, %s, %s, %s )\"\n",
    "            cursor.execute(sql, (review_code, store_code, user_id, rating, comment, timestamp))\n",
    "        self.conn.commit()\n",
    "    \n",
    "\n",
    "\n",
    "rating_df = pd.DataFrame()\n",
    "restaurant_df = pd.DataFrame()\n",
    "db = DBHelper()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "##### 메인 코드 #####\n",
    "def main():\n",
    "    global driver, load_wb, review_num, local, number_local, number_store\n",
    "\n",
    "    driver.implicitly_wait(4)  # 렌더링 될때까지 기다린다 4초\n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "\n",
    "     #### 검색할 목록\n",
    "    place_infos = ['종로구 맛집', '중구 맛집', ' 용산구 맛집', '성동구 맛집', '광진구 맛집', '동대문구 맛집', '중랑구 맛집', '성북구 맛집', '강북구 맛집']\n",
    "#     place_infos = ['도봉구 맛집', '노원구 맛집', '은평구 맛집', '서대문구 맛집', '마포구 맛집', '양천구 맛집', '강서구 맛집','구로구 맛집']\n",
    "#     place_infos = ['금천구 맛집', '영등포구 맛집', '동작구 맛집', '관악구 맛집', '서초구 맛집', '강남구 맛집', '송파구 맛집','강동구 맛집']\n",
    "\n",
    "    for i, place in enumerate(place_infos):\n",
    "        print(\"##### {0} : {1}\".format(i,place))\n",
    "        number_local = 0\n",
    "        number_store = 0\n",
    "        \n",
    "        local = read_local_code(place)\n",
    "        search(place, local)\n",
    "        create_csv_file(place)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"finish\")\n",
    "\n",
    "#     db.db_selectKeyword_STORE()\n",
    "#     db.db_selectKeyword_REVIEW()\n",
    "    \n",
    "\n",
    "\n",
    "#### 가게 정보 찾기\n",
    "def search(place, local):\n",
    "    \"\"\"\n",
    "    검색한 페이지 음식점 정보 크롤링 하는 함수\n",
    "    :param place: 리뷰 정보 찾을 장소이름\n",
    "    :param local : 지역구 코드\n",
    "    \"\"\"\n",
    "    global driver\n",
    "\n",
    "    search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')  # 검색 창\n",
    "    search_area.send_keys(place)  # 검색어 입력\n",
    "    driver.find_element_by_xpath('//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER) # 더보기\n",
    "    \n",
    "    xPath = '//*[@id=\"info.search.page.no1\"]'\n",
    "    driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER) # 첫번째 페이지로 이동\n",
    "    sleep(1)\n",
    "\n",
    "    # 검색된 정보가 있는 경우에만 탐색\n",
    "    # 1번 페이지 place list 읽기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem') # 검색된 장소 목록\n",
    "\n",
    "    # 검색된 첫 페이지 장소 목록 크롤링하기\n",
    "    crawling(place, local, place_lists)\n",
    "\n",
    "    # 전체 페이지\n",
    "    while True:\n",
    "        try:\n",
    "#            2~ 5페이지 읽기\n",
    "            for i in range(2, 6):\n",
    "                # 페이지 넘기기\n",
    "                xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "                driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                place_lists = soup.select('.placelist > .PlaceItem') # 장소 목록 list\n",
    "                \n",
    "                crawling(place, local, place_lists)\n",
    "                \n",
    "                # 다음 페이지 넘기기\n",
    "                if i==5:\n",
    "                    driver.find_element_by_xpath('//*[@id=\"info.search.page.next\"]').send_keys(Keys.ENTER)\n",
    "\n",
    "        except ElementNotInteractableException:\n",
    "            print('end page')\n",
    "            break\n",
    "            \n",
    "        finally:\n",
    "            search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')\n",
    "            search_area.clear()\n",
    "\n",
    "\n",
    "#### 가게 정보 크롤링 하기\n",
    "def crawling(place, local, place_lists):\n",
    "    \"\"\"\n",
    "    페이지 목록을 받아서 크롤링 하는 함수\n",
    "    :param place: 리뷰 정보 찾을 장소이름\n",
    "    :param local : 지역구 코드\n",
    "    :param place_lists : 페이지 내에 있는 음식점 목록\n",
    "    \"\"\"\n",
    "    \n",
    "    global restaurant_df, number_store, db\n",
    "\n",
    "    while_flag = False\n",
    "    for i, place in enumerate(place_lists):\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text  # place name\n",
    "        place_address = place.select('.info_item > .addr > p')[0].text  # place address\n",
    "        place_local = place.select('.info_item > .addr > .lot_number')[0].text\n",
    "        place_category = place.select('.head_item > .subcategory')[0].text\n",
    "        place_detail = place.select('.info_item > .contact> .moreview')[0].get('href') # place detail\n",
    "        \n",
    "        number_store += 1\n",
    "        store_code = str('STORE_') + local + str(number_store).zfill(4) # 가게 코드 (ex. STORE_GC0001)\n",
    "        \n",
    "        store_Info = STORE_Info(store_code, place_name, place_address, place_local, place_category)\n",
    "#         store_Info.data_check()\n",
    "        \n",
    "        \n",
    "        #### DataFrame 저장 ####\n",
    "        row = {'store_code': store_code, \"ItemID\":place_name, \"address\": place_address, \"local\" : place_local, \"category\": place_category}\n",
    "        row = pd.DataFrame(row, index=[1])\n",
    "        restaurant_df = restaurant_df.append(row, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        #### 데이터 베이스 저장 #####\n",
    "        db.db_insertCrawlingData_STORE(store_code, place_name, place_address, place_local, place_category)\n",
    "        \n",
    "\n",
    "        \n",
    "        #### 리뷰 크롤링 ####\n",
    "        driver.execute_script('window.open(\"about:blank\", \"_blank\");')\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        driver.get(place_detail) # 상세정보 탭으로 변환\n",
    "        sleep(1)\n",
    "        \n",
    "        print('####', place_name)\n",
    "        sleep(1)\n",
    "        # 첫 페이지\n",
    "        extract_review(place_name, store_code , local) # 리뷰 추출\n",
    "\n",
    "        # 2-5 페이지\n",
    "        idx = 3\n",
    "        try:\n",
    "            page_num = len(driver.find_elements_by_class_name('link_page')) # 페이지 수 찾기\n",
    "            for i in range(page_num-1):\n",
    "                # css selector를 이용해 페이지 버튼 누르기\n",
    "                driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "                extract_review(place_name, store_code, local)\n",
    "                idx += 1\n",
    "            driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 5페이지가 넘는 경우 다음 버튼 누르기\n",
    "            \n",
    "            sleep(1)\n",
    "            extract_review(place_name, store_code, local) # 리뷰 추출\n",
    "            \n",
    "            # 그 이후 페이지\n",
    "            while True:\n",
    "                idx = 4\n",
    "                page_num = len(driver.find_elements_by_class_name('link_page')) #페이지 수 찾기\n",
    "                for i in range(page_num-1):\n",
    "                    driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                    sleep(1)\n",
    "                    extract_review(place_name, store_code, local)\n",
    "                    idx += 1\n",
    "                driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\n",
    "                sleep(1)\n",
    "                extract_review(place_name, store_code, local) # 리뷰 추출            \n",
    "            \n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            print(\"no review in crawling\")\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])  # 검색 탭으로 전환\n",
    "\n",
    "\n",
    "#### 리뷰 크롤링 하기\n",
    "def extract_review(place_name, store_code, local):\n",
    "    \"\"\"\n",
    "    리뷰 크롤링 하는 함수\n",
    "    :param place_place: 리뷰 정보 찾을 장소이름\n",
    "    :param local : 지역구 코드\n",
    "    \"\"\"\n",
    "    \n",
    "    global driver, rating_df, number_local, db\n",
    "\n",
    "    ret = True\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 첫 페이지 리뷰 목록 찾기\n",
    "    review_lists = soup.select('.list_evaluation > li')\n",
    "\n",
    "    # 리뷰가 있는 경우\n",
    "    if len(review_lists) != 0:\n",
    "        for i, review in enumerate(review_lists):\n",
    "            comment = review.select('.txt_comment > span') # 리뷰\n",
    "            rating = review.select('.grade_star > em') # 별점\n",
    "            user_id = review.select('.append_item > a[data-userid]') # user-id 정보 html 파싱\n",
    "#             user_name = review.select('.append_item > a[data-username]') # user-name 정보 html 파싱\n",
    "            timestamp = review.select(' div > span.time_write') #시간정보\n",
    "            number_local += 1\n",
    "                  \n",
    "\n",
    "            #### 리뷰 클래스에 정보 담기 ####\n",
    "            review_info = REVIEW_Info()\n",
    "            \n",
    "            review_info.review_code = local + str(number_local).zfill(6) # 리뷰 코드 (ex. GC000001)\n",
    "            review_info.store_code = store_code\n",
    "            \n",
    "\n",
    "            if len(comment) != 0: # 리뷰\n",
    "                if comment[0].text:\n",
    "                    review_info.comment = comment[0].text \n",
    "                else:\n",
    "                    review_info.comment = None\n",
    "            else:\n",
    "                review_info.comment = None\n",
    "            \n",
    "            if len(rating) != 0: # 별점\n",
    "                review_info.rating = rating[0].text.replace('점', '')\n",
    "            else:\n",
    "                review_info.rating = None\n",
    "\n",
    "            if(len(user_id) != 0): # 유저id\n",
    "                if(user_id[0].get('data-userid')):\n",
    "                    review_info.user_id = user_id[0].get('data-userid')\n",
    "                else:\n",
    "                    review_info.user_id = None\n",
    "            else:\n",
    "                review_info.user_id = None\n",
    "\n",
    "            if len(timestamp) != 0: # 시간\n",
    "                review_info.timestamp = timestamp[0].text\n",
    "            else:\n",
    "                review_info.timestamp = None\n",
    "                \n",
    "#             review_info.data_check()\n",
    "            \n",
    "            \n",
    "            \n",
    "            #### DB 에 정보 담기 ####\n",
    "            db.db_insertCrawlingData_REVIEW(review_info.review_code, review_info.store_code, review_info.user_id, review_info.rating, review_info.comment, review_info.timestamp)\n",
    "            \n",
    "            \n",
    "            #### DataFrame 에 정보 담기 ####\n",
    "            try:\n",
    "                row = {\"review_code\" : review_info.review_code, \"place_code\": review_info.store_code, \"ItemID\": place_name, \n",
    "                       \"UserID\":review_info.user_id, \"review\" : review_info.comment,\n",
    "                       \"Rating\":review_info.rating, \"Timestamp\":review_info.timestamp}\n",
    "                row = pd.DataFrame(row, index=[i])\n",
    "                rating_df = rating_df.append(row, ignore_index=True)\n",
    "            \n",
    "            except:\n",
    "                row = {\"review_code\" : review_info.review_code, \"place_code\": store_code, \"ItemID\":place_name, \n",
    "                       \"UserID\": None, \"review\" : None, \"Rating\":None, \"Timestamp\":review_info.timestamp}\n",
    "                row = pd.DataFrame(row, index=[i])\n",
    "                rating_df = rating_df.append(row, ignore_index=True)\n",
    "                \n",
    "    else:\n",
    "        print('no review in extract')\n",
    "        ret = False\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "#### CSV 파일로 저장 ####\n",
    "def create_csv_file(place):\n",
    "    global rating_df, restaurant_df\n",
    "\n",
    "    rating_df.to_csv('%s_rating_df.csv' %place)\n",
    "    rating_df.to_csv('%s_rating_df_ko.csv' %place, sep=',', na_rep='NaN', encoding='utf-8-sig')\n",
    "        \n",
    "    restaurant_df.to_csv('%s_restaurant_df.csv'  %place)\n",
    "    restaurant_df.to_csv('%s_restaurant_df_ko.csv'  %place, sep=',', na_rep='NaN', encoding='utf-8-sig')\n",
    "    \n",
    "    \n",
    "\n",
    "#### 지역구 코드 뽑아오기 ####\n",
    "def read_local_code(place):\n",
    "    \n",
    "    local_place = place.split(' ')[0]\n",
    "\n",
    "    local_code = pd.read_csv('local_code.csv', encoding='utf-8', index_col = 'local')\n",
    "    return local_code.at[local_place, 'local_code']\n",
    "\n",
    "#### 메인 ####\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b75993ed-3284-47a6-9519-3c36ff2614f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_code</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GC000001</td>\n",
       "      <td>호세가</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021.06.14.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GC000002</td>\n",
       "      <td>호세가</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021.06.04.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GC000003</td>\n",
       "      <td>호세가</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021.06.02.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GC000004</td>\n",
       "      <td>호세가</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021.05.18.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GC000005</td>\n",
       "      <td>호세가</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021.05.15.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>GC003230</td>\n",
       "      <td>용호동낙지 가산점</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021.01.08.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>GC003231</td>\n",
       "      <td>용호동낙지 가산점</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020.01.31.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>GC003232</td>\n",
       "      <td>용호동낙지 가산점</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018.12.16.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>GC003233</td>\n",
       "      <td>용호동낙지 가산점</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018.08.29.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>GC003234</td>\n",
       "      <td>용호동낙지 가산점</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016.12.27.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3234 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_code     ItemID UserID review Rating    Timestamp\n",
       "0       GC000001        호세가   None   None   None  2021.06.14.\n",
       "1       GC000002        호세가   None   None   None  2021.06.04.\n",
       "2       GC000003        호세가   None   None   None  2021.06.02.\n",
       "3       GC000004        호세가   None   None   None  2021.05.18.\n",
       "4       GC000005        호세가   None   None   None  2021.05.15.\n",
       "...          ...        ...    ...    ...    ...          ...\n",
       "3229    GC003230  용호동낙지 가산점   None   None   None  2021.01.08.\n",
       "3230    GC003231  용호동낙지 가산점   None   None   None  2020.01.31.\n",
       "3231    GC003232  용호동낙지 가산점   None   None   None  2018.12.16.\n",
       "3232    GC003233  용호동낙지 가산점   None   None   None  2018.08.29.\n",
       "3233    GC003234  용호동낙지 가산점   None   None   None  2016.12.27.\n",
       "\n",
       "[3234 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7c4f1-08db-4081-b3dc-0c1bffb166a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
